{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ea08bc-c757-406f-acfc-fe1ecd8b057e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from typing import Set, Dict, List, Tuple\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "class RadiationAnalysisPipeline:\n",
    "    def __init__(self, vcf_dir: str, output_dir: str, metadata_file: str):\n",
    "\n",
    "       \n",
    "        self.vcf_dir = vcf_dir\n",
    "        self.output_dir = output_dir\n",
    "        self.plots_dir = os.path.join(output_dir, 'plots')\n",
    "        self.filtered_dir = os.path.join(output_dir, 'filtered_vcfs')\n",
    "        \n",
    "        \n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "        os.makedirs(self.plots_dir, exist_ok=True)\n",
    "        os.makedirs(self.filtered_dir, exist_ok=True)\n",
    "        \n",
    "        \n",
    "        self.setup_logging()\n",
    "        \n",
    "        \n",
    "        self.logger.info(\"Initializing RadiationAnalysisPipeline...\")\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            self.metadata = pd.read_csv(metadata_file)\n",
    "            self.logger.info(f\"Read metadata for {len(self.metadata)} samples\")\n",
    "            self.logger.info(f\"Metadata columns: {self.metadata.columns.tolist()}\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error reading metadata file: {str(e)}\")\n",
    "            raise\n",
    "        \n",
    "        \n",
    "        self.analysis_results = pd.DataFrame()\n",
    "        self.control_variants = set()\n",
    "        \n",
    "        self.logger.info(\"Pipeline initialization complete\")\n",
    "\n",
    "    def setup_logging(self):\n",
    "        \"\"\"Configure logging for the pipeline.\"\"\"\n",
    "        log_file = os.path.join(self.output_dir, \n",
    "                               f'radiation_analysis_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log')\n",
    "        \n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "            handlers=[\n",
    "                logging.FileHandler(log_file),\n",
    "                logging.StreamHandler()\n",
    "            ]\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def read_vcf_with_headers(self, vcf_file: str) -> Tuple[List[str], pd.DataFrame]:\n",
    "        \"\"\"Read a VCF file while preserving headers and data structure.\"\"\"\n",
    "        self.logger.info(f\"Reading VCF file: {vcf_file}\")\n",
    "        headers = []\n",
    "        variant_data = []\n",
    "        \n",
    "        try:\n",
    "            with open(vcf_file, 'r') as f:\n",
    "                for line in f:\n",
    "                    if line.startswith('#'):\n",
    "                        headers.append(line)\n",
    "                        if line.startswith('#CHROM'):\n",
    "                            column_names = line.strip('#\\n').split('\\t')\n",
    "                    else:\n",
    "                        variant_data.append(line.strip().split('\\t'))\n",
    "            \n",
    "            df = pd.DataFrame(variant_data, columns=column_names)\n",
    "            self.logger.info(f\"Successfully read {len(df)} variants\")\n",
    "            return headers, df\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error reading VCF file {vcf_file}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def process_treatment_sample(self, sample: str) -> Dict:\n",
    "        \"\"\"Process a single treatment sample using metadata information.\"\"\"\n",
    "        input_vcf = os.path.join(self.vcf_dir, f\"{sample}.vcf\")\n",
    "        output_vcf = os.path.join(self.filtered_dir, f\"{sample}_filtered.vcf\")\n",
    "        \n",
    "        # Get sample metadata\n",
    "        sample_meta = self.metadata[self.metadata['SampleName'] == sample].iloc[0]\n",
    "        \n",
    "        # Read and process the file\n",
    "        headers, variants_df = self.read_vcf_with_headers(input_vcf)\n",
    "        \n",
    "        # Create variant identifiers\n",
    "        variants_df['variant_id'] = variants_df.apply(\n",
    "            lambda row: f\"{row['CHROM']}_{row['POS']}_{row['REF']}_{row['ALT']}\", \n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # Filter variants\n",
    "        filtered_df = variants_df[~variants_df['variant_id'].isin(self.control_variants)]\n",
    "        \n",
    "        # Write filtered VCF\n",
    "        with open(output_vcf, 'w') as f:\n",
    "            for header in headers:\n",
    "                f.write(header)\n",
    "            for _, row in filtered_df.iterrows():\n",
    "                variant_line = '\\t'.join(str(row[col]) for col in variants_df.columns \n",
    "                                       if col != 'variant_id')\n",
    "                f.write(f\"{variant_line}\\n\")\n",
    "        \n",
    "        # Calculate statistics using metadata information\n",
    "        stats = {\n",
    "            'Sample': sample,\n",
    "            'Total_Variants': len(variants_df),\n",
    "            'Radiation_Specific_Variants': len(filtered_df),\n",
    "            'Filtered_Out': len(variants_df) - len(filtered_df),\n",
    "            'Percent_Specific': round(len(filtered_df) / len(variants_df) * 100, 2),\n",
    "            'Week': int(sample.split('_W')[1][0]),\n",
    "            'Exposure_Rate': sample_meta['ExposureRate_mGh'],\n",
    "            'Total_Exposure': sample_meta['TotalExposure_mG']\n",
    "        }\n",
    "        \n",
    "        return stats\n",
    "\n",
    "    def process_all_samples(self):\n",
    "        \"\"\"Process all treatment samples while filtering out variants found in controls.\"\"\"\n",
    "        self.logger.info(\"Starting analysis of treatment samples...\")\n",
    "        \n",
    "        # First, identify control samples from metadata\n",
    "        control_samples = self.metadata[\n",
    "            self.metadata['ExposureRate_mGh'].astype(str).str.lower() == 'control'\n",
    "        ]['SampleName'].tolist()\n",
    "        \n",
    "        # Collect control variants\n",
    "        self.logger.info(\"Collecting variants from control samples...\")\n",
    "        self.control_variants = set()\n",
    "        \n",
    "        for control_sample in control_samples:\n",
    "            control_vcf = os.path.join(self.vcf_dir, f\"{control_sample}.vcf\")\n",
    "            if os.path.exists(control_vcf):\n",
    "                headers, variants_df = self.read_vcf_with_headers(control_vcf)\n",
    "                variant_ids = variants_df.apply(\n",
    "                    lambda row: f\"{row['CHROM']}_{row['POS']}_{row['REF']}_{row['ALT']}\", \n",
    "                    axis=1\n",
    "                )\n",
    "                self.control_variants.update(variant_ids)\n",
    "                self.logger.info(f\"Added {len(variant_ids)} variants from {control_sample}\")\n",
    "        \n",
    "        self.logger.info(f\"Found {len(self.control_variants)} unique variants in control samples\")\n",
    "        \n",
    "        # Process treatment samples\n",
    "        results = []\n",
    "        treatment_samples = self.metadata[\n",
    "            self.metadata['ExposureRate_mGh'].astype(str).str.lower() != 'control'\n",
    "        ]['SampleName'].tolist()\n",
    "        \n",
    "        for sample in treatment_samples:\n",
    "            self.logger.info(f\"Processing treatment sample: {sample}\")\n",
    "            try:\n",
    "                stats = self.process_treatment_sample(sample)\n",
    "                results.append(stats)\n",
    "                self.logger.info(f\"Successfully processed {sample}\")\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Error processing sample {sample}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        # Create analysis results DataFrame\n",
    "        self.analysis_results = pd.DataFrame(results)\n",
    "        \n",
    "        # Save results to CSV\n",
    "        results_file = os.path.join(self.output_dir, 'analysis_results.csv')\n",
    "        self.analysis_results.to_csv(results_file, index=False)\n",
    "        self.logger.info(f\"Analysis results saved to: {results_file}\")\n",
    "        \n",
    "        # Log summary statistics\n",
    "        self.logger.info(\"\\nAnalysis Summary:\")\n",
    "        self.logger.info(f\"Total samples processed: {len(results)}\")\n",
    "        self.logger.info(f\"Average radiation-specific variants: \"\n",
    "                        f\"{self.analysis_results['Radiation_Specific_Variants'].mean():.2f}\")\n",
    "        self.logger.info(f\"Average percent specific: \"\n",
    "                        f\"{self.analysis_results['Percent_Specific'].mean():.2f}%\")\n",
    "\n",
    "    def create_visualizations(self):\n",
    "        \"\"\"Create comprehensive visualizations of the radiation analysis results.\"\"\"\n",
    "        self.logger.info(\"Creating visualizations...\")\n",
    "        \n",
    "        # Set up the plotting style\n",
    "        plt.style.use('seaborn')\n",
    "        \n",
    "        # Create a figure with multiple subplots\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20, 15))\n",
    "        \n",
    "        # Plot 1: Variants by Exposure Rate\n",
    "        scatter = ax1.scatter(self.analysis_results['Exposure_Rate'], \n",
    "                            self.analysis_results['Radiation_Specific_Variants'],\n",
    "                            c=self.analysis_results['Week'],\n",
    "                            s=150,\n",
    "                            cmap='viridis',\n",
    "                            alpha=0.7)\n",
    "        ax1.set_xscale('log')\n",
    "        ax1.set_title('Radiation-Specific Variants vs Exposure Rate', pad=20)\n",
    "        ax1.set_xlabel('Exposure Rate (mGh)')\n",
    "        ax1.set_ylabel('Number of Radiation-Specific Variants')\n",
    "        plt.colorbar(scatter, ax=ax1, label='Week')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 2: Variants Over Time\n",
    "        for rate in sorted(self.analysis_results['Exposure_Rate'].unique()):\n",
    "            rate_data = self.analysis_results[self.analysis_results['Exposure_Rate'] == rate]\n",
    "            ax2.plot(rate_data['Week'], \n",
    "                    rate_data['Radiation_Specific_Variants'],\n",
    "                    marker='o',\n",
    "                    label=f'{rate} mGh',\n",
    "                    linewidth=2,\n",
    "                    markersize=8)\n",
    "        ax2.set_title('Accumulation of Radiation-Specific Variants Over Time', pad=20)\n",
    "        ax2.set_xlabel('Week')\n",
    "        ax2.set_ylabel('Number of Radiation-Specific Variants')\n",
    "        ax2.legend(title='Exposure Rate (mGh)', bbox_to_anchor=(1.05, 1))\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 3: Bubble Plot\n",
    "        scatter = ax3.scatter(self.analysis_results['Total_Exposure'],\n",
    "                            self.analysis_results['Percent_Specific'],\n",
    "                            s=self.analysis_results['Radiation_Specific_Variants']/1000,\n",
    "                            c=self.analysis_results['Week'],\n",
    "                            cmap='viridis',\n",
    "                            alpha=0.6)\n",
    "        ax3.set_xscale('log')\n",
    "        ax3.set_title('Percentage of Radiation-Specific Variants vs Total Exposure', pad=20)\n",
    "        ax3.set_xlabel('Total Exposure (mG)')\n",
    "        ax3.set_ylabel('Percent Specific (%)')\n",
    "        plt.colorbar(scatter, ax=ax3, label='Week')\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add bubble size legend\n",
    "        max_variants = self.analysis_results['Radiation_Specific_Variants'].max()\n",
    "        legend_elements = [plt.scatter([], [], s=s/1000, c='gray', alpha=0.6,\n",
    "                                     label=f'{s:,} variants')\n",
    "                          for s in [500000, 1000000, 1500000]]\n",
    "        ax3.legend(handles=legend_elements, title='Number of Variants',\n",
    "                  bbox_to_anchor=(1.05, 0.5))\n",
    "        \n",
    "        # Plot 4: Heatmap\n",
    "        pivot_data = self.analysis_results.pivot(index='Exposure_Rate',\n",
    "                                               columns='Week',\n",
    "                                               values='Radiation_Specific_Variants')\n",
    "        sns.heatmap(pivot_data, ax=ax4, \n",
    "                    annot=True,\n",
    "                    fmt=',d',\n",
    "                    cmap='YlOrRd',\n",
    "                    cbar_kws={'label': 'Number of Variants'})\n",
    "        ax4.set_title('Distribution of Radiation-Specific Variants\\nAcross Time and Exposure Rates', \n",
    "                     pad=20)\n",
    "        ax4.set_xlabel('Week')\n",
    "        ax4.set_ylabel('Exposure Rate (mGh)')\n",
    "        \n",
    "        # Save the plots\n",
    "        plt.tight_layout()\n",
    "        plot_path = os.path.join(self.plots_dir, 'radiation_analysis_summary.png')\n",
    "        plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        self.logger.info(\"Visualizations completed and saved\")\n",
    "\n",
    "def run_analysis(vcf_dir: str, output_dir: str, metadata_file: str):\n",
    "    \"\"\"Run the complete radiation analysis pipeline.\"\"\"\n",
    "    pipeline = RadiationAnalysisPipeline(vcf_dir, output_dir, metadata_file)\n",
    "    pipeline.process_all_samples()\n",
    "    pipeline.create_visualizations()\n",
    "    return pipeline\n",
    "\n",
    "# usage\n",
    "if __name__ == \"__main__\":\n",
    "    vcf_directory = \"./LDR/vcf_files/all_samples/vcf\"\n",
    "    output_directory = \"./radiation_analysis_results\"\n",
    "    metadata_file = \"./LDR/vcf_files/all_samples/meta_data.csv\"\n",
    "    \n",
    "    pipeline = run_analysis(vcf_directory, output_directory, metadata_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f31afb-4542-4fe9-a1fc-dcf70a4f610e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SigProfilerMatrixGenerator import install as genInstall\n",
    "genInstall.install('GRCh38')  # Or 'GRCh37' if your VCF uses that build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb51d09-acf9-4f3f-937a-83ae4fb21b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from SigProfilerExtractor import sigpro as sig\n",
    "\n",
    "# Run SigProfilerExtractor and store results\n",
    "def run_sigprofiler_analysis(input_data, output_dir, project_name):\n",
    "    \"\"\"Run SigProfilerExtractor and return results\"\"\"\n",
    "    try:\n",
    "        results = sig.sigProfilerExtractor(\n",
    "            input_type=\"vcf\",\n",
    "            output=output_dir,\n",
    "            input_data=input_vcf,\n",
    "            reference_genome=\"GRCh38\",\n",
    "            minimum_signatures=1,\n",
    "            maximum_signatures=10,\n",
    "            nmf_replicates=100,\n",
    "            cpu=-1 #Can add GPU option here\n",
    "        )\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error running SigProfilerExtractor: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126f896b-dcef-48b5-997a-d4d76ca73334",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./radiation_analysis_results/filtered_vcfs/output/\"\n",
    "input_vcf = \"./radiation_analysis_results/filtered_vcfs/\"\n",
    "project_name =\"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df038a1-994e-4bf4-b2a3-e86a7ca9bc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_sigprofiler_analysis(input_vcf,output_dir, project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7cd741-8d6d-4167-8f0c-7152cc5f67ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
