{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a709134-8529-4022-b78e-9b8d3e5e5eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e851804b-7a4e-4a23-b420-a787ac03f27e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def parse_vcf_to_hgvs(vcf_file):\n",
    "    \"\"\"\n",
    "    Parse a VCF file and convert the variants to HGVS notation.\n",
    "    \"\"\"\n",
    "    variants_info = []\n",
    "    # Read the VCF file with proper header handling\n",
    "    with open(vcf_file, 'r') as f:\n",
    "        # Skip header lines starting with ##\n",
    "        header = None\n",
    "        for line in f:\n",
    "            if line.startswith('#CHROM'):\n",
    "                header = line.strip().split('\\t')\n",
    "                break\n",
    "        \n",
    "        # Read the rest of the file as DataFrame\n",
    "        df = pd.read_csv(f, sep='\\t', names=header)\n",
    "    \n",
    "    # Iterate over each row and construct variant information\n",
    "    for _, row in df.iterrows():\n",
    "        chrom = row['#CHROM']\n",
    "        pos = row['POS']\n",
    "        ref = row['REF']\n",
    "        alt = row['ALT']\n",
    "        \n",
    "        # Safely parse INFO field\n",
    "        try:\n",
    "            info_fields = [item.split('=') for item in row['INFO'].split(';') if '=' in item]\n",
    "            info_dict = {k: v for k, v in info_fields}\n",
    "        except:\n",
    "            info_dict = {}\n",
    "            \n",
    "        variant_type = info_dict.get('VT', 'Unknown')\n",
    "        variant_class = info_dict.get('VC', 'Unknown')\n",
    "        \n",
    "        # Create HGVS notation\n",
    "        hgvs_variant = f\"{chrom}:g.{pos}{ref}>{alt}\"\n",
    "        \n",
    "        # Store all relevant information\n",
    "        variant_info = {\n",
    "            'hgvs': hgvs_variant,\n",
    "            'chromosome': chrom,\n",
    "            'position': pos,\n",
    "            'ref_allele': ref,\n",
    "            'alt_allele': alt,\n",
    "            'variant_type': variant_type,\n",
    "            'variant_classification': variant_class\n",
    "        }\n",
    "        \n",
    "        variants_info.append(variant_info)\n",
    "        \n",
    "    print(f\"Processed {len(variants_info)} variants from {vcf_file}\")\n",
    "    return variants_info\n",
    "\n",
    "def query_ensembl_vep_batch(variants):\n",
    "    \"\"\"\n",
    "    Query the Ensembl VEP REST API for a batch of variants (GRCh38).\n",
    "    \"\"\"\n",
    "    server = \"https://rest.ensembl.org\"\n",
    "    ext = \"/vep/human/hgvs\"\n",
    "    headers = {\"Content-Type\": \"application/json\", \"Accept\": \"application/json\"}\n",
    "    \n",
    "    data = {\n",
    "        \"hgvs_notations\": variants,\n",
    "        \"fields\": [\"canonical\", \"biotype\", \"consequence_terms\", \"transcript_id\", \"gene_symbol\", \"protein_id\"]\n",
    "    }\n",
    "    \n",
    "    response = requests.post(f\"{server}{ext}\", headers=headers, data=json.dumps(data))\n",
    "    if not response.ok:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "        response.raise_for_status()\n",
    "    \n",
    "    return response.json()\n",
    "\n",
    "def query_with_retries(batch, retries=3):\n",
    "    \"\"\"\n",
    "    Query Ensembl VEP for a single batch with retry logic.\n",
    "    \"\"\"\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            return query_ensembl_vep_batch(batch)\n",
    "        except Exception as e:\n",
    "            if attempt < retries - 1:\n",
    "                print(f\"Retrying batch... Attempt {attempt + 2}\")\n",
    "            else:\n",
    "                print(f\"Failed after {retries} attempts: {e}\")\n",
    "                raise\n",
    "\n",
    "def parallel_batch_query_ensembl_vep(variants, batch_size=200, max_workers=4):\n",
    "    \"\"\"\n",
    "    Parallelize Ensembl VEP batch queries using ThreadPoolExecutor.\n",
    "    \"\"\"\n",
    "    batches = [variants[i:i + batch_size] for i in range(0, len(variants), batch_size)]\n",
    "    all_results = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_batch = {executor.submit(query_with_retries, batch): batch for batch in batches}\n",
    "\n",
    "        for future in as_completed(future_to_batch):\n",
    "            batch = future_to_batch[future]\n",
    "            try:\n",
    "                results = future.result()\n",
    "                all_results.extend(results)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing batch: {batch[:5]}... -> {e}\")\n",
    "\n",
    "    return all_results\n",
    "\n",
    "def parse_vep_results(results, sample_name, variant_info):\n",
    "    \"\"\"\n",
    "    Parse the VEP API results and return a DataFrame.\n",
    "    \"\"\"\n",
    "    parsed_data = []\n",
    "    for result, var_info in zip(results, variant_info):\n",
    "        variant = result.get(\"input\")\n",
    "        gene = result.get(\"gene_symbol\", \"N/A\")\n",
    "        transcript_consequences = result.get(\"transcript_consequences\", [])\n",
    "        \n",
    "        for transcript in transcript_consequences:\n",
    "            entry = {\n",
    "                \"Sample\": sample_name,\n",
    "                \"Variant\": variant,\n",
    "                \"Chromosome\": var_info['chromosome'],\n",
    "                \"Position\": var_info['position'],\n",
    "                \"Reference_Allele\": var_info['ref_allele'],\n",
    "                \"Alternative_Allele\": var_info['alt_allele'],\n",
    "                \"Variant_Type\": var_info['variant_type'],\n",
    "                \"Variant_Classification\": var_info['variant_classification'],\n",
    "                \"Gene\": gene,\n",
    "                \"Transcript\": transcript.get(\"transcript_id\"),\n",
    "                \"Biotype\": transcript.get(\"biotype\"),\n",
    "                \"VEP_Consequence\": transcript.get(\"consequence_terms\", [\"N/A\"])[0],\n",
    "                \"Protein\": transcript.get(\"protein_id\", \"N/A\")\n",
    "            }\n",
    "            parsed_data.append(entry)\n",
    "    \n",
    "    return pd.DataFrame(parsed_data)\n",
    "\n",
    "def plot_consequence_distribution(df, title, output_file):\n",
    "    \"\"\"\n",
    "    Plot the distribution of variant consequences using seaborn.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(data=df, y=\"VEP_Consequence\", \n",
    "                  order=df[\"VEP_Consequence\"].value_counts().index, \n",
    "                  palette=\"coolwarm\")\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel(\"Count\", fontsize=14)\n",
    "    plt.ylabel(\"Consequence\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_file)\n",
    "    plt.show()\n",
    "\n",
    "# --- Main Script ---\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Input directory containing VCF files\n",
    "input_directory = \"./\"  # Replace with  VCF files directory\n",
    "\n",
    "# Get the list of all VCF files in the directory\n",
    "vcf_files = glob.glob(os.path.join(input_directory, \"*.vcf\"))\n",
    "\n",
    "# Check if VCF files are found\n",
    "if not vcf_files:\n",
    "    raise ValueError(f\"No VCF files found in the directory: {input_directory}\")\n",
    "\n",
    "print(f\"VCF files to process: {len(vcf_files)} files\")\n",
    "\n",
    "combined_results = []\n",
    "\n",
    "# Initialize the progress bar for files\n",
    "file_progress = tqdm(vcf_files, desc=\"Processing VCF Files\", unit=\"file\")\n",
    "\n",
    "for vcf_file in file_progress:\n",
    "    sample_name = os.path.splitext(os.path.basename(vcf_file))[0]\n",
    "\n",
    "    # Parse VCF file and get all variant information\n",
    "    variants_info = parse_vcf_to_hgvs(vcf_file)\n",
    "\n",
    "    # Extract just HGVS notations for VEP query\n",
    "    hgvs_variants = [v['hgvs'] for v in variants_info]\n",
    "\n",
    "    # Query Ensembl VEP API with parallel processing\n",
    "    print(f\"Processing {len(hgvs_variants)} variants for sample: {sample_name}\")\n",
    "    batch_progress = tqdm(\n",
    "        total=len(hgvs_variants),\n",
    "        desc=f\"Annotating {sample_name}\",\n",
    "        unit=\"variant\",\n",
    "    )\n",
    "    def progress_tracking_batch(batch):\n",
    "        result = query_with_retries(batch)\n",
    "        batch_progress.update(len(batch))\n",
    "        return result\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        batches = [hgvs_variants[i:i + 200] for i in range(0, len(hgvs_variants), 200)]\n",
    "        future_to_batch = {executor.submit(progress_tracking_batch, batch): batch for batch in batches}\n",
    "        vep_results = []\n",
    "        for future in as_completed(future_to_batch):\n",
    "            vep_results.extend(future.result())\n",
    "    batch_progress.close()\n",
    "\n",
    "    # Parse VEP results with additional information\n",
    "    df_sample = parse_vep_results(vep_results, sample_name, variants_info)\n",
    "\n",
    "    # Save individual sample results to CSV\n",
    "    sample_results_file = f\"{sample_name}_vep_results.csv\"\n",
    "    df_sample.to_csv(sample_results_file, index=False)\n",
    "    print(f\"Saved sample results to {sample_results_file}\")\n",
    "\n",
    "    # Plot consequences for the sample\n",
    "    plot_consequence_distribution(df_sample, f\"Variant Consequences for {sample_name}\", f\"{sample_name}_consequence_plot.png\")\n",
    "\n",
    "    # Add the sample results to the combined DataFrame\n",
    "    combined_results.append(df_sample)\n",
    "\n",
    "file_progress.close()\n",
    "\n",
    "# Combine results from all samples into one DataFrame\n",
    "df_combined = pd.concat(combined_results, ignore_index=True)\n",
    "\n",
    "# Save combined results to a CSV file\n",
    "df_combined_file = \"./combined_vep_results.csv\"\n",
    "df_combined.to_csv(df_combined_file, index=False)\n",
    "print(f\"Saved combined results to {df_combined_file}\")\n",
    "\n",
    "# Plot combined consequences\n",
    "plot_consequence_distribution(df_combined, \"Combined Variant Consequences for All Samples\", \"./combined_consequence_plot.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866011d1-280e-4246-abc7-d4c560498559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_nucleotide_change(variant):\n",
    "    \"\"\"\n",
    "    Extract the specific nucleotide change (e.g., T>C, C>T) from the Variant column.\n",
    "    :param variant: Variant string in the form '1:g.809687G>C'\n",
    "    :return: Nucleotide change (e.g., G>C, C>T)\n",
    "    \"\"\"\n",
    "    ref = variant.split('>')[0][-1]  # Reference allele\n",
    "    alt = variant.split('>')[1]  # Alternate allele\n",
    "    return f\"{ref}>{alt}\"\n",
    "\n",
    "def plot_nucleotide_change_distribution(df, output_file):\n",
    "    \"\"\"\n",
    "    Plot the distribution of specific nucleotide changes as a bar plot.\n",
    "    :param df: Pandas DataFrame containing nucleotide changes\n",
    "    :param output_file: Path to save the plot image\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.countplot(data=df, y=\"Nucleotide_Change\", palette=\"coolwarm\", order=df[\"Nucleotide_Change\"].value_counts().index)\n",
    "    plt.title(\"Nucleotide Change Distribution\", fontsize=16)\n",
    "    plt.xlabel(\"Count\", fontsize=14)\n",
    "    plt.ylabel(\"Nucleotide Change\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_file)\n",
    "    plt.show()\n",
    "    \n",
    "# Load the combined VEP results from the CSV file\n",
    "combined_vep_file = \"combined_vep_results.csv\"  # Replace with the path to your combined VEP CSV file\n",
    "df_combined = pd.read_csv(combined_vep_file)\n",
    "\n",
    "# Add a Nucleotide_Change column by extracting specific changes (e.g., T>C, C>T)\n",
    "df_combined['Nucleotide_Change'] = df_combined['Variant'].apply(classify_nucleotide_change)\n",
    "\n",
    "# Save the updated DataFrame with nucleotide changes\n",
    "df_combined.to_csv(\"combined_vep_with_nucleotide_changes.csv\", index=False)\n",
    "# Plot the distribution of specific nucleotide changes (e.g., T>C, C>T)\n",
    "plot_nucleotide_change_distribution(df_combined, \"combined_nucleotide_change_plot.png\")\n",
    "\n",
    "# Display the DataFrame with nucleotide changes\n",
    "print(df_combined[['Variant', 'Nucleotide_Change']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e512bb37-0cc9-4de3-9889-b21d0bccc30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transcript_mutation_distribution(df, output_file):\n",
    "    \"\"\"\n",
    "    Plot the distribution of mutations affecting transcripts.\n",
    "    :param df: Pandas DataFrame containing VEP results\n",
    "    :param output_file: Path to save the plot image\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    top_transcripts = df['Transcript'].value_counts().nlargest(20)  # Top 20 most affected transcripts\n",
    "    sns.barplot(y=top_transcripts.index, x=top_transcripts.values, palette=\"coolwarm\")\n",
    "    plt.title(\"Top 20 Transcripts Affected by Mutations\", fontsize=16)\n",
    "    plt.xlabel(\"Mutation Count\", fontsize=14)\n",
    "    plt.ylabel(\"Transcript\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_file)\n",
    "    plt.show()\n",
    "\n",
    "# Plot transcript-specific mutation distribution\n",
    "plot_transcript_mutation_distribution(df_combined, \"transcript_mutation_distribution.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7319262c-b7c5-499b-8b81-16980f6e5379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_shared_mutations(df, output_file):\n",
    "    \"\"\"\n",
    "    Plot the distribution of mutations shared across samples.\n",
    "    :param df: Pandas DataFrame containing VEP results\n",
    "    :param output_file: Path to save the plot image\n",
    "    \"\"\"\n",
    "    shared_mutations = df['Variant'].value_counts()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(shared_mutations, bins=30, kde=False, color='skyblue')\n",
    "    plt.title(\"Distribution of Shared Mutations Across Samples\", fontsize=16)\n",
    "    plt.xlabel(\"Number of Samples Sharing a Mutation\", fontsize=14)\n",
    "    plt.ylabel(\"Count of Mutations\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_file)\n",
    "    plt.show()\n",
    "\n",
    "# Plot the distribution of shared mutations\n",
    "plot_shared_mutations(df_combined, \"shared_mutations_distribution.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3353aecc-d2dc-4be4-9dee-f72c9910a339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_biotype_distribution(df, output_file):\n",
    "    \"\"\"\n",
    "    Plot the distribution of biotype categories from the VEP results.\n",
    "    :param df: Pandas DataFrame containing VEP results\n",
    "    :param output_file: Path to save the plot image\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(data=df, y=\"Biotype\", order=df[\"Biotype\"].value_counts().index, palette=\"coolwarm\")\n",
    "    plt.title(\"Biotype Distribution of Variants\", fontsize=16)\n",
    "    plt.xlabel(\"Count\", fontsize=14)\n",
    "    plt.ylabel(\"Biotype\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_file)\n",
    "    plt.show()\n",
    "\n",
    "# Load combined VEP results from the CSV file\n",
    "#combined_vep_file = \"combined_vep_results.csv\"  # Replace with your file path\n",
    "#df_combined = pd.read_csv(combined_vep_file)\n",
    "\n",
    "# Plot biotype distribution\n",
    "plot_biotype_distribution(df_combined, \"biotype_distribution_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53331a0-88be-4554-9ab6-89e3a94bf050",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (py39)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
